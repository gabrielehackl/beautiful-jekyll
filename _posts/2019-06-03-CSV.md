---
layout: post
title: Merging Data for Georeferencing - with Update
subtitle: Creating a CSV-file out of multiple Python dictionaries




---
Extracting toponyms (place names) from the “Dispatch” (python), calculating their frequencies, putting the result into a CSV-file; also putting the issue date (for the time stamp) in another dictionary with the frequencies as well; using this to compare the found toponyms with the toponyms of another dictionary made from 'US.txt' (named 'dicGeonames', storing the coordinates) to write a cvs that includes the coordinates as well;
Problem was: the CSV-output is empty for a reason unknown...

~~~
import re, os, csv
origPath = "C:/Users/hackl/Documents/Seminare/DH_Methodenkurs/MAPPING/Homework/"
newPath = "C:/Users/hackl/Documents/Seminare/DH_Methodenkurs/MAPPING/HomeworkMAP/"

lof = os.listdir(origPath)
dicFreq = {}#create a dict that can be compared to a gazette or tgn
dicFreqIssueDate = {}#create a dict that stores everything under the time stamp
listPlaceNames = []#create a list for toponymes
resultsCSV = []#create a list for results 1 (dict with only names and frequency)
resultsCSV2 = []#create a list for results 2 (dict with time stamp)
geonames = []
dicGeonames = {}

for f in lof:
    with open(origPath + f, "r", encoding="utf8") as file:
        text = file.read()
        # try to find the date and articles
        issueDate = re.search(r"[0-9]{4}-[0-9]{2}-[0-9]{2}", text).group(0)
        dicFreqIssueDate[issueDate] = {}
        allarticles = re.findall(r'(?s)<div3 type="article"(.*?)</div3>', text)

        for article in allarticles:
            #find all the results between opening and closing tag "placeName" with regex
            placeNames = re.findall(r'<placeName(.*?)</placeName>', text)

            # go through all the results checking for the keys reg=, key= and authname=?
            for place in placeNames:
                if "reg" in place and "key" in place and "authname" in place:
                    #if all three keys are present we will use the information after reg=
                    match = re.search(r'reg="([a-zA-Z].*?)(,|")', place)
                    if match:
                        place = match.group(1).upper()
                        # see if place is in the dict, otherwise write it with the value 1, count up for every futher mention
                        if place in dicFreq:
                            dicFreq[place] += 1
                        else:
                            dicFreq[place] = 1            
                        if place in dicFreqIssueDate: # making a dict in a dict to store everything under a time stamp
                            dicFreqIssueDate[issueDate][place] += 1
                        else:
                            dicFreqIssueDate[issueDate][place] = 1            

# dicFreq into csv-format
for place, frequency in dicFreq.items():    
    if frequency > 1:# this will exclude items with frequency 1 as they are not of importance usually
        newVal = "%09d\t%s" % (frequency, place)
        # newVal looks like: `000005486 TAB Richmond`
        resultsCSV.append(newVal)

resultsCSV = sorted(resultsCSV, reverse=True)
resultsToSave = "\n".join(resultsCSV)

# saving
with open(newPath+"dispatch_CSV.csv", "w", encoding="utf8") as f9:
    f9.write(resultsToSave)

# read coords
with open("C:/Users/hackl/Documents/Seminare/DH_Methodenkurs/MAPPING/"+"US.txt", "r", encoding="utf8") as file:
    text = file.read()

    data = text.split('\n') # split into lines so we can go trough them one by one

    for line in data: # writing the dictionary going through every line
        tab = line.split('\t') # splits every line into a list, so we can loop trough it
        if len(tab) >= 5:      
            dicGeonames[tab[1].upper()] = [tab[4],tab[5]] #defining key and value (values as list as recommended)
        else:
            print(tab)#to see if there are empty entries for example

# dicFreq into csv-format with time stamp and such
for issueDate, dicFreq in dicFreqIssueDate.items():
    for place, frequency in dicFreq.items():
        # this will exclude items with frequency 1 as they are not of importance usually
        if frequency > 1 and place in dicGeonames:
            newVal2 = "%s\t%s\t%s\t%s\t%09d" % (place, issueDate, dicGeonames[place][0], dicGeonames[place][1], frequency)
            # newVal2 looks like: 'Richmond TAB ...'
            resultsCSV2.append(newVal2)

resultsCSV2 = sorted(resultsCSV2, reverse=True)
resultsToSave2 = "\n".join(resultsCSV2)

# saving into a csv
with open(newPath+"dispatch_CSV2.csv", "w", encoding="utf8") as f9:
    f9.write(resultsToSave2)

~~~

Update: instead of nesting dictinaries I created (with some help) a dictionary with a key including two infos, namely the place and the time stamp, splitting that key up to write into the csv; works fine now :)

~~~
import re, os, csv
origPath = "Homework/"
newPath = "HomeworkMAP/"

lof = os.listdir(origPath)
dicFreq = {}#create a dict that can be compared to a gazette or tgn
dicFreqIssueDate = {}
listPlaceNames = []
resultsCSV = []
resultsCSV2 = []
geonames = []
dicGeonames = {}

print("Start processing")

for f in lof:
    print("Analysing file " + f)
    with open(origPath + f, "r", encoding="utf8") as file:
        text = file.read()
        # try to find the date and articles
        issueDate = re.search(r"[0-9]{4}-[0-9]{2}-[0-9]{2}", text).group(0)
        allarticles = re.findall(r'(?s)<div3 type="article"(.*?)</div3>', text)

        for article in allarticles:
            #find all the results between opening and closing tag "placeName" with regex
            # CHANGED! hier stand "text", daher wurden alle places über alle article gesucht, für jeden aritcle, weshalb die zahlen viel zu hoch waren
            placeNames = re.findall(r'<placeName(.*?)</placeName>', article)

            # go through all the results checking for the keys reg=, key= and authname=?
            for place in placeNames:
                if "reg" in place and "key" in place and "authname" in place:
                    #if all three keys are present we will use the information after reg=
                    match = re.search(r'reg="([a-zA-Z].*?)(,|")', place)
                    if match:
                        place = match.group(1).upper()
                        key = place + "##" + issueDate
                        # see if place is in the dict, otherwise write it with the value 1, count up for every futher mention
                        if place in dicFreq:
                            dicFreq[place] += 1
                        else:
                            dicFreq[place] = 1
                        # CHANGED! hier stand "place in dicFreqIssueDate"
                        # mit dem dict in dict hätte das "place in dicFreqIssueDate[issueDate]" sein müssen, dadurch war freq immer 1 und dann kam unten nichts raus
                        # mit dem ansatz den dein prof wollte, nun "key in dicFreqIssueDate" dann gehts auch
                        if key in dicFreqIssueDate:
                            dicFreqIssueDate[key] += 1
                        else:
                            dicFreqIssueDate[key] = 1

print("Writing result to " + newPath+"dispatch_CSV.csv")
# dicFreq into csv-format
for place, frequency in dicFreq.items():    
    if frequency > 1:# this will exclude items with frequency 1 as they are not of importance usually
        newVal = "%09d\t%s" % (frequency, place)
        # newVal will looks like: `000005486 TAB Richmond`
        resultsCSV.append(newVal)

resultsCSV = sorted(resultsCSV, reverse=True)
resultsToSave = "\n".join(resultsCSV)

# saving
with open(newPath+"dispatch_CSV.csv", "w", encoding="utf8") as f9:
    f9.write(resultsToSave)

print("Parsing US.txt")        
# read coords
with open(origPath + "../US.txt", "r", encoding="utf8") as file:
    text = file.read()
    data = text.split('\n') # split into lines so we can go trough them one by one
    for line in data: # writing the dictionary going through every line
        tab = line.split('\t') # splits every line into a list, so we can loop trough it
        if len(tab) > 5:
            dicGeonames[tab[1].upper()] = [tab[4],tab[5]] #defining key and value (values as list as recommended)

print("Writing map to " + newPath+"dispatch_CSV2.csv")
# dicFreq into csv-format with time stamp and such
for placeIssueDate, frequency in dicFreqIssueDate.items():
    [place, issueDate] = placeIssueDate.split('##')
    # this will exclude items with frequency 1 as they are not of importance usually
    if frequency > 1 and place in dicGeonames:
        newVal2 = "%s\t%s\t%s\t%s\t%d" % (place, issueDate, dicGeonames[place][0], dicGeonames[place][1], frequency)
        # newVal will looks like: `000005486 TAB Richmond`
        resultsCSV2.append(newVal2)

resultsCSV2 = sorted(resultsCSV2, reverse=True)
resultsToSave2 = "\n".join(resultsCSV2)

# saving
with open(newPath+"dispatch_CSV2.csv", "w", encoding="utf8") as f9:
    f9.write(resultsToSave2)
~~~
